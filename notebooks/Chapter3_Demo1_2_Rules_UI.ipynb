{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74968,"status":"ok","timestamp":1740056026558,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"},"user_tz":180},"id":"fVx2RMFYRnky","outputId":"2ac1f071-603e-4946-aa2f-b5b5213baea2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Collecting gradio\n","  Downloading gradio-5.16.2-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.7.1 (from gradio)\n","  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Collecting markupsafe~=2.0 (from gradio)\n","  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.1->gradio) (14.2)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-5.16.2-py3-none-any.whl (62.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.7.1-py3-none-any.whl (321 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markupsafe, ffmpy, aiofiles, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: markupsafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.16.2 gradio-client-1.7.1 markupsafe-2.1.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"]}],"source":["!pip install torch transformers gradio flask peft"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1740056026601,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"},"user_tz":180},"id":"OOjXczjWR885"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10687,"status":"ok","timestamp":1740056037289,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"},"user_tz":180},"id":"2TlZpSQMRoRa","outputId":"02baffa8-f641-41fd-a133-7e2d3c53c88e"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-02-20 12:53:46--  https://www.dropbox.com/scl/fi/5s6bkx3k7ja7f6gul87s0/flan_t5_finetuned_opus_books_lora.zip?rlkey=ygbswjmgzfwwf707pt08eli46\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.85.18, 2620:100:6035:18::a27d:5512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.85.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com/cd/0/inline/CkdrN6ER_Nz1o1ZysISnCuUavpnYtDBeLq0cbSZaBXcK2ios68F05mRyKF_c3v1vugrkgB6ADBYGZscQPi6A5bcd_Uc204Yhp8j1UWF5Liq7WhOb2zNbjLvDBg1wURdi1buhlXeEyUYW-0KLAqMCBy3f/file# [following]\n","--2025-02-20 12:53:47--  https://ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com/cd/0/inline/CkdrN6ER_Nz1o1ZysISnCuUavpnYtDBeLq0cbSZaBXcK2ios68F05mRyKF_c3v1vugrkgB6ADBYGZscQPi6A5bcd_Uc204Yhp8j1UWF5Liq7WhOb2zNbjLvDBg1wURdi1buhlXeEyUYW-0KLAqMCBy3f/file\n","Resolving ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com (ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com)... 162.125.85.15, 2620:100:6030:15::a27d:500f\n","Connecting to ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com (ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com)|162.125.85.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/Ckd3Yps4uw0c0tvgrjfIBgUIwFWlJm5HHWitGVajF79yUp-h8vJFLJqt_46j_eZ3zCvgB0deYEFN_lrcAIcJuVOFaJCVlqEeBqzww3OA4gpDj1l5ucCPaxJ2hLNucCKW_8ZeE72eYjrBpWlol_eCZiMEfpnpySbrydrGb8uB8sk9Lg7oNGNpllypIWy7KyFKX1uSx_q1oArS3W5sznSx9wEfYoU_JcqaIjGcLTc-ootCKUlkj9lNMOI-kfqvrmbvNKkqWOA6WWW3qC3solT9tVFmZfSZmoKE24hweO1sYwQM7g2NySwWB5tGRpktznng6CvEXCw8nnywNFeW6Pm8jHiB1AY523Z0gV12X0PmsuRXLqVlBo8HgVlCGrfQ4R-kNLE/file [following]\n","--2025-02-20 12:53:48--  https://ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com/cd/0/inline2/Ckd3Yps4uw0c0tvgrjfIBgUIwFWlJm5HHWitGVajF79yUp-h8vJFLJqt_46j_eZ3zCvgB0deYEFN_lrcAIcJuVOFaJCVlqEeBqzww3OA4gpDj1l5ucCPaxJ2hLNucCKW_8ZeE72eYjrBpWlol_eCZiMEfpnpySbrydrGb8uB8sk9Lg7oNGNpllypIWy7KyFKX1uSx_q1oArS3W5sznSx9wEfYoU_JcqaIjGcLTc-ootCKUlkj9lNMOI-kfqvrmbvNKkqWOA6WWW3qC3solT9tVFmZfSZmoKE24hweO1sYwQM7g2NySwWB5tGRpktznng6CvEXCw8nnywNFeW6Pm8jHiB1AY523Z0gV12X0PmsuRXLqVlBo8HgVlCGrfQ4R-kNLE/file\n","Reusing existing connection to ucab07421d79187dd3fd85a85779.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 123266546 (118M) [application/zip]\n","Saving to: ‘lora_finetune.zip’\n","\n","lora_finetune.zip   100%[===================>] 117.56M  22.1MB/s    in 6.4s    \n","\n","2025-02-20 12:53:55 (18.4 MB/s) - ‘lora_finetune.zip’ saved [123266546/123266546]\n","\n","Archive:  lora_finetune.zip\n","   creating: flan_t5_finetuned_opus_books_lora/\n","  inflating: flan_t5_finetuned_opus_books_lora/tokenizer_config.json  \n","  inflating: flan_t5_finetuned_opus_books_lora/README.md  \n","  inflating: flan_t5_finetuned_opus_books_lora/tokenizer.json  \n","  inflating: flan_t5_finetuned_opus_books_lora/adapter_model.safetensors  \n","  inflating: flan_t5_finetuned_opus_books_lora/adapter_config.json  \n","  inflating: flan_t5_finetuned_opus_books_lora/special_tokens_map.json  \n","  inflating: flan_t5_finetuned_opus_books_lora/spiece.model  \n","adapter_config.json\t   README.md\t\t    spiece.model\t   tokenizer.json\n","adapter_model.safetensors  special_tokens_map.json  tokenizer_config.json\n"]}],"source":["\n","!wget -O lora_finetune.zip https://www.dropbox.com/scl/fi/5s6bkx3k7ja7f6gul87s0/flan_t5_finetuned_opus_books_lora.zip?rlkey=ygbswjmgzfwwf707pt08eli46&st=t819ej0f&dl=0\n","!unzip lora_finetune.zip\n","!ls flan_t5_finetuned_opus_books_lora\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"75lpa3EwR0-l","executionInfo":{"status":"ok","timestamp":1740056377466,"user_tz":180,"elapsed":57393,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"8bc821e5-5b54-4677-d7b2-2b1884c32f5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://fa2331684062c22f4a.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://fa2331684062c22f4a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://fa2331684062c22f4a.gradio.live\n"]}],"source":["import re\n","import torch\n","import gradio as gr\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSeq2SeqLM,\n","    AutoConfig,\n","    pipeline,\n","    logging\n",")\n","from peft import PeftModel\n","\n","# Optional: reduce logging verbosity.\n","logging.set_verbosity_error()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ---------------- Ethical Filtering ----------------\n","banned_words = [\"hate\", \"kill\", \"stupid\", \"idiot\", \"terrorist\", \"bomb\", \"nazi\", \"racist\", \"sexist\"]\n","\n","def contains_banned_words(text: str) -> bool:\n","    text = text or \"\"\n","    text_lower = text.lower()\n","    for word in banned_words:\n","        if re.search(r\"\\b\" + re.escape(word) + r\"\\b\", text_lower):\n","            return True\n","    return False\n","\n","# ---------------- Sentiment Analysis ----------------\n","sentiment_pipeline = pipeline(\n","    \"sentiment-analysis\",\n","    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",")\n","\n","# ---------------- Model Loading ----------------\n","base_checkpoint = \"google/flan-t5-large\"\n","adapter_checkpoint = \"flan_t5_finetuned_opus_books_lora\"  # local folder with adapter files\n","\n","# Load the base model and tokenizer.\n","tokenizer = AutoTokenizer.from_pretrained(base_checkpoint)\n","model = AutoModelForSeq2SeqLM.from_pretrained(\n","    base_checkpoint,\n","    torch_dtype=torch.float16,\n","    device_map=\"cuda\"\n",")\n","# Load the LoRA adapter from local files.\n","model = PeftModel.from_pretrained(model, adapter_checkpoint, local_files_only=True)\n","model.to(device)\n","\n","# ---------------- Response Function ----------------\n","def respond(message: str,\n","            history: list,  # history is managed automatically by Gradio.\n","            system_message: str,\n","            max_tokens: int,\n","            temperature: float,\n","            top_p: float):\n","    \"\"\"\n","    Respond to the user's message.\n","    - Applies ethical filtering and sentiment checks.\n","    - Builds a prompt using the system message and current user message.\n","    - Generates a response using our LoRA-finetuned FLAN-T5-large model.\n","    Returns a single string reply.\n","    \"\"\"\n","    if message is None or message.strip() == \"\":\n","        return \"\"\n","\n","    # Ethical filtering.\n","    if contains_banned_words(message):\n","        return \"I'm sorry, but I cannot engage with that request.\"\n","\n","    # Sentiment analysis.\n","    sentiment = sentiment_pipeline(message)[0]\n","    if sentiment[\"label\"] == \"NEGATIVE\" and sentiment[\"score\"] > 0.85:\n","        return \"I sense some negativity in your message. Let's try to keep our conversation respectful.\"\n","\n","    # Build prompt: use the system message plus the current user message.\n","    prompt = system_message + \"\\nUser: \" + message + \"\\nBot: \"\n","    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    # Ensure sampling parameters are in effect.\n","    outputs = model.generate(\n","        **inputs,\n","        max_length=max_tokens,\n","        do_sample=True,\n","        temperature=temperature,\n","        top_p=top_p,\n","        num_beams=4,\n","        early_stopping=True\n","    )\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    # Remove the prompt from the output if it's there.\n","    if response.startswith(prompt):\n","        response = response[len(prompt):].strip()\n","    return response\n","\n","# ---------------- Gradio Chat Interface ----------------\n","demo = gr.ChatInterface(\n","    fn=respond,\n","    type=\"messages\",  # This indicates that the conversation history is maintained by Gradio.\n","    title=\"Ethical Chatbot\",\n","    description=\"Chatbot using a LoRA-finetuned FLAN-T5-large model for responses and DistilBERT for sentiment analysis with ethical filtering.\",\n","    additional_inputs=[\n","        gr.Textbox(value=\"You are a friendly Chatbot. Please respond helpfully.\", label=\"System message\"),\n","        gr.Slider(minimum=1, maximum=2048, value=150, step=1, label=\"Max new tokens\"),\n","        gr.Slider(minimum=0.1, maximum=4.0, value=0.7, step=0.1, label=\"Temperature\"),\n","        gr.Slider(minimum=0.1, maximum=1.0, value=0.95, step=0.05, label=\"Top-p (nucleus sampling)\")\n","    ]\n",")\n","\n","if __name__ == \"__main__\":\n","    demo.launch(debug=True, share=True)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AXWxzn3GU0vu","executionInfo":{"status":"ok","timestamp":1740056318997,"user_tz":180,"elapsed":3,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMe9E6atj8Xmart91upBvsq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}